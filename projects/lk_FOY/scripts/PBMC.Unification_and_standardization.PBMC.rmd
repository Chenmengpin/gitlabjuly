```{r setup, echo=FALSE}
opts_chunk$set(tidy=TRUE, cache=FALSE,  highlight=TRUE, figalign="center", echo=TRUE, warning=FALSE, error=FALSE, message=FALSE, tidy.opts=list(keep.blank.line=FALSE, width.cutoff=120), fig.path="figure/PBMC-unify-", cache.path="cache/PBMC-unify-")
options(width=200)
```

# UNIFICATION AND STANDARDIZATION OF PBMC STUDIES

---

Analysis of public PBMC datasets for differential gene expression signatures between adults and children for [Les Kobzik](mailto:LKOBZIK@hsph.harvard.edu) as part of the DARPA 7-day Biodefense Program.

Contact [John Hutchinson](mailto:jhutchin@hsph.harvard.edu) for additional details.

The most recent update of this html document occurred: `r date()`

The sections below provide code to reproduce the included results and plots. 

----

# GENERAL SETUP

## General purpose R libraries necessary for analysis

```{r general_libraries}
source("http://bioconductor.org/biocLite.R") # BioConductor script necessary for installing new BioC libraries with biocLite()
library(xtable) # table generation for reports
library(plyr) # library for iteratively working with data structures
library(ggplot2) # library for plotting 
library(RColorBrewer) # library for generating color palettes
library(googleVis) # library for presenting tables
```

## Locations of directories for data, metadata and results

```{r general_directories}
if (file.exists("/n/hsphS10/hsphfs1/chb/projects/lk_FOY")) {
  baseDir <- "/n/hsphS10/hsphfs1/chb/projects/lk_FOY"
  }  else if (file.exists("/Volumes/home08/jhutchin/consults/lk_FOY/")) {
    baseDir <- "/Volumes/home08/jhutchin/consults/lk_FOY"
    } else {
      baseDir <- "/Volumes/ody/consults/lk_FOY"
      }
dataDir <- file.path(baseDir, "data")
resultsDir <- file.path(baseDir, "results", "PBMC")
metaDir <- file.path(baseDir, "meta", "PBMC")
````

----

# CURATION and UNIFICATION OF DATA
## Obtaining metadata for all studies 

In this section, I downloaded the metadata for all the PBMC studies Les shared in his [PBMC U133Plus2 MasterList](../meta/PBMC/MasterListPBMCsU133Plus2.xlsx) and his [Summary of U133A PBMC datasets](../meta/PBMC/SummaryU133APBMCdataMay302013.xlsx).

I used two [Bioconductor][1] libraries to interface with the [Gene Expression Omnibus][2] and [Array Express][3] databases ([GEOquery][4] and [ArrayExpress][5] respectively). 

```{r database_download_libraries}
library(GEOquery)
library(ArrayExpress)
```

### Load in the series IDs of the GEO studies
The IDs of the GEO series (GSEs) are:

```{r GEOIDs}
GSE.ids <- c("GSE27562","GSE11761","GSE14642","GSE34205","GSE20307","GSE11083","GSE10041","GSE29619","GSE22255","GSE17114","GSE21942","GSE43553", "GSE7148", "GSE8650", "GSE9006", "GSE11909", "GSE12517", "GSE6269")
print(GSE.ids)
```

**There are `r length(GSE.ids)` GEO series in total**

### Data for each GEO series was downloaded via GEOquery into separate directories by series ID
For series with more than one dataset (GDS), I numbered the metadata files separately, according to their order in the series  metadata. 
For series with only one dataset, the metadata file contains the number "1"

```{r GEOquerypDATA, eval=FALSE}
for (GSE.id in GSE.ids) {
  # name of the directory receiveing the files
  gse.dataDir=file.path(dataDir, GSE.id) 
  # check to see if this directory exists already 
  if (!(file.exists(gse.dataDir))) { 
    # if it does not, create it
    dir.create(gse.dataDir) 
    }
  # pull down the available series data, using exception handling (i.e. try())
  gse <- try(getGEO(GSE.id, destdir=gse.dataDir)) 
  # for every dataset within the series
  for(n in 1:length(gse)){ 
    # grab the metadata
    metadata <- pData(gse[[n]]) 
     # discard columns you aren't interested in
    metadata <- metadata[,!grepl("data_row_count|status|submission_date|last_update_date|channel_count|scan_protocol|data_processing|hyb_protocol|taxid_ch1|label|contact", names(metadata))]
    # filename to writout the metadata, contains the series id and the number of the dataset 
    file.out <- paste("metadata", GSE.id, n, "tab", sep=".") 
    # write out to tab-delimited file, retaining column names
    write.table(metadata, file=file.path(gse.dataDir, file.out), quote=F, sep="\t", col.names=T, row.names=F) 
    # sleep 5 seconds between downloads so you don't hammer the GEO server, as it seems to be a bit unstable
    Sys.sleep(5) 
    }
  }
```


As withthe whole blood studies, these GEO metadata files were then individually hand examined to determine, if available:  
1. column headers for:
- unique sample identifier (GSM id)
- sample type
- age
- gender
- ethnicity
- FTP location for raw data
- microarray platform
- series ID
- database
2. regular expressions to identify:
- the raw data file
- the control samples

To allow later extraction of the relevant subset of each study's metadata, these values were then compiled in a [columnID translator table](../meta/PBMC/columnid.translator.PBMC.tab).

## Preparing Curated Metadata from Les
Les provided a Excel files with manually curated metadata for 24 studies, each with its own worksheet within the file. These files were modified and combined combined to make a [new file](../meta/PBMC/MasterListPBMCsU133JH.xlsx)  with:  
1. a column with the study ID in every sheet
2. consistent columns headers between sheets
3. platform information for each study

Each curated study's sheet of metadata from this new Excel file was extracted into a table in the study's directory for later import into R.

```{r extract_curated_metadata, eval=FALSE}
library(gdata)
for (sheetnum in 1:12){
  print(sheetnum)
  metadata <- read.xls(file.path(metaDir, "MasterListPBMCsU133JH.xlsx"), sheet=sheetnum)
  study <- unique(metadata$study)
  write.table(metadata, file=file.path(dataDir, study, paste("curated.metadata", study, "tab", sep=".")), row.names=F, col.names=T, sep="\t", quote=F)
} 
```

## Unifying the metadata into a single file
The goal here was to obtain a metadata file that combined the downloaded metadata and the curated metadata, using the "columnID translator"" as a guide. 

```{r unify_metadata, eval=FALSE}
## load in the columnID translator
template <- read.table(file.path(metaDir, "columnid.translator.PBMC.tab"), header=T, colClasses="character", sep="\t") 
## setup list to receive results, each study will be an element in the list
output.l <- list() 
for(rownum in 1:nrow(template)) {
  colids <- template[rownum,] 
  study <- colids$study
  print(study)
  print(rownum)
  list.index <- colids$list.index
  database <- colids$Database
  study.metadata <- read.delim(file.path(dataDir, study, paste("metadata", study, list.index, "tab", sep="." )), header=T, sep="\t") # pull in the study metadata for the local directory
  ## get sampleIDs
  if (is.na(colids$sampleID)) {sampleIDs <- rep(NA, nrow(study.metadata))} else { sampleIDs <- study.metadata[,colids$sampleID]} # if there are no sampleIDs, fill with NA
  ## get sampletypes
  if(is.na(colids$sampltype_col.1)){
     ## if there is no sampletype column #1, fill with NA's
    sampletypes=rep("control", nrow(study.metadata))
  } else {
    # if there is no sampletype column #2, but there is a sampletype column #1, take values from sampletype column #1
    if(is.na(colids$sampletype_col.2)){ 
      sampletypes <- study.metadata[,colids$sampltype_col.1]
    } else {
      # if there are two columns that describe the sampletype, grab them both and paste them together
      sampletypes <- paste(study.metadata[,colids$sampltype_col.1], study.metadata[,colids$sampletype_col.2]) 
    }
  }
  # get ages, fill with NA if no column identified
  if (is.na(colids$age_col)) {ages <- rep(NA, nrow(study.metadata))} else { ages <- study.metadata[,colids$age_col]} 
  # get genders, fill with NA if no column identified   
  if (is.na(colids$gender_col)) {genders <- rep(NA, nrow(study.metadata))} else { genders <- study.metadata[,colids$gender_col]}
  # get ethnicities, fill with NA if no column identified   
  if (is.na(colids$ethnicity_col)) {ethnicities <- rep(NA, nrow(study.metadata))} else { ethnicities <- study.metadata[,colids$ethnicity_col]}
  # get FTP locations of cel files, fill with NA if no column identified   
  if (is.na(colids$CEL_FTP_col)) {CEL_FTPs <- rep(NA, nrow(study.metadata))} else { CEL_FTPs <- study.metadata[,colids$CEL_FTP_col]}
  # get CEL regex identifiers to enable pulling from local directories, fill with NA if no column identified   
  if (is.na(colids$CEL_regex_col)) {CEL_regexes <- rep(NA, nrow(study.metadata))} else { CEL_regexes <- study.metadata[,colids$CEL_regex_col]}
  # get platformid, fill with NA if no column identified   
  if (is.na(colids$platformid_col)) {platformids <- rep(NA, nrow(study.metadata))} else { platformids <- study.metadata[,colids$platformid_col]}
  # make dataframe
  sample.metadata.sub <- as.data.frame(cbind(as.character(sampleIDs), as.character(sampletypes), as.character(ages), as.character(genders), as.character(ethnicities), as.character(CEL_FTPs), as.character(CEL_regexes), as.character(platformids)))
  names(sample.metadata.sub) <- c("sampleID", "sampletype", "age", "gender", "ethnicity", "CEL_FTP", "CEL_regex", "platform")
  sample.metadata.sub$study <- study # fill in columns with study ID and database ID
  sample.metadata.sub$database <- database
  # subset to the control samples using the control sampletype regex for that study
  # adjust for cases where multiple regexes are necessary to identify a control sample
  if (is.na(colids$control_regex.2) & !is.na(colids$control_regex.1)) { 
    sample.metadata.sub <- sample.metadata.sub[grep(colids$control_regex.1, sample.metadata.sub$sampletype),]
  } else if (!is.na(colids$control_regex.2) & !is.na(colids$control_regex.1)){
    sample.metadata.sub <- sample.metadata.sub[intersect(grep(colids$control_regex.1, sample.metadata.sub$sampletype), grep(colids$control_regex.2, sample.metadata.sub$sampletype)),]
  }
  # if curated data exists for this study, replace what you downloaded from GEO/ArrayExpress with his curated data
  if(file.exists(file.path(dataDir, study, paste("curated.metadata", study, "tab", sep=".")))){
    curated.metadata <- read.table(file.path(dataDir, study, paste("curated.metadata", study, "tab", sep=".")), sep="\t", header=T)
    # find the columns you are going to replace in the original downloaded metadata
    replace.cols <- setdiff(names(sample.metadata.sub)[names(sample.metadata.sub) %in% names(curated.metadata)], c("sampleID", "study", "database"))    
    for (replace.col in replace.cols){
      # convert replacement column to characters, otherwise error
      sample.metadata.sub[,replace.col] <- as.character(sample.metadata.sub[,replace.col])
      # subset the curation data dataframe to relevant ids 
      curated.metadata <- curated.metadata[(curated.metadata$sampleID %in% sample.metadata.sub$sampleID),]
      # replace the columns in the original metadata dataframe with the sampleID matched curated metadata
      sample.metadata.sub[,replace.col][na.omit(match(curated.metadata$sampleID,sample.metadata.sub$sampleID))] <- as.character(curated.metadata[,replace.col])
    }
  }
  # output the control sample metadata for the study
  output.l[[rownum]] <- sample.metadata.sub 
}
# collapse the metadata list into a dataframe
output <- do.call(rbind, output.l) 
# output to file
write.table(output, file.path(metaDir, "unified.metadata.unrefined.PBMC.tab"), quote=F, col.names=T, row.names=F, sep="\t")
```

GSE10041 did not have any gender data, so samples were clusterd by 5 sex-specific genes and genders [assigned](./PBMC.sex.determination.html). Ages of 38 years were assigned to all these samples. This information was then incorporated into the unrefined and refined metadata files.

The file with the unified (but not consistent) metadata can be found [here](../meta/PBMC/unified.metadata.unrefined.PBMC.tab)
*(this is a tab-delimited file that can be opened in Excel)*
The end goal is a file containing the metadata for all control samples in all studies. To generate a file that can be then be used to load in the metadata and its respective raw data later in the analysis, I also needed consistent labeling of gender, age, ethnicity, FTP location, and CEL file search terms etc. 

To make this file, I ran the "unified.metadata.unrefined.PBMC.tab" file through [Google refine][6], merging multiple terms for the same thing into a single term. For example, terms such as "F", "Female", "Fem", and "f" were merged into the single term FEMALE. All ages were converted to years based units. For ethnicity, African Origin encompasses the terms: "African American, Afro-American, Black, African etc.". Asian encompasses the terms: "Chinese, Asian, Indian and Oriental". Caucasian encompasses the terms: " White and Caucasian".

The unified, refined metadata file can be found [here](../meta/PBMC/unified.metadata.refined.PBMC.tab)
*(this is a tab-delimited file that can be opened in Excel)*

---

A separate [python script](./PBMC.download.cels.py) was used to download all the GEO CEL files (using their ftp locations from the metadata file). 

[1]: http://www.bioconductor.org (BioC)
[2]: http://www.ncbi.nlm.nih.gov/gds/ (GEO)
[3]: http://www.ebi.ac.uk/arrayexpress/ (ArrayExpress)
[4]: http://www.bioconductor.org/packages/2.11/bioc/html/GEOquery.html (GEOquery_BioC_library)
[5]: http://www.bioconductor.org/packages/2.11/bioc/html/ArrayExpress.html (ArrayExpress_BioC_library)
[6]: https://code.google.com/p/google-refine/ (Google_Refine)


